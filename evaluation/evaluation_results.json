{
  "pretrained": {
    "lstm": [
      {
        "model_name": "LSTM (Pretrain Epoch 1)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 6.598843565412388,
        "perplexity": 734.2455910869755,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_1.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 2)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 5.884673543796418,
        "perplexity": 359.48539260217217,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_2.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 3)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 5.392017063821197,
        "perplexity": 219.64597899198571,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_3.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 4)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.9055494119407265,
        "perplexity": 2.4732904051216242,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_4.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 5)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.2333237764182364,
        "perplexity": 1.2627902748566908,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_5.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 6)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.09227901001929477,
        "perplexity": 1.096670761529081,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_6.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 7)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.04947522816479586,
        "perplexity": 1.0507195636405615,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_7.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 8)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.03347358697206731,
        "perplexity": 1.0340401312347074,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_8.pt"
      },
      {
        "model_name": "LSTM (Pretrain Final)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.03347358697206731,
        "perplexity": 1.0340401312347074,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstm_pretrained_final.pt"
      }
    ],
    "gpt": [
      {
        "model_name": "GPT (Pretrain Epoch 1)",
        "display_name": "Transformer",
        "language_modeling_loss": 6.5218730944736745,
        "perplexity": 679.850617896896,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_1.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 2)",
        "display_name": "Transformer",
        "language_modeling_loss": 5.930223449779923,
        "perplexity": 376.2385748594306,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_2.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 3)",
        "display_name": "Transformer",
        "language_modeling_loss": 5.537786732813355,
        "perplexity": 254.11495231591834,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_3.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 4)",
        "display_name": "Transformer",
        "language_modeling_loss": 5.187369155276353,
        "perplexity": 178.997019573785,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_4.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 5)",
        "display_name": "Transformer",
        "language_modeling_loss": 4.900893858283948,
        "perplexity": 134.40986938054522,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_5.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 6)",
        "display_name": "Transformer",
        "language_modeling_loss": 0.862915633590358,
        "perplexity": 2.3700608586920393,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_6.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 7)",
        "display_name": "Transformer",
        "language_modeling_loss": 0.0865257082708702,
        "perplexity": 1.0903793991264024,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_7.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 8)",
        "display_name": "Transformer",
        "language_modeling_loss": 0.030759327244132186,
        "perplexity": 1.0312372832988292,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_8.pt"
      },
      {
        "model_name": "GPT (Pretrain Final)",
        "display_name": "Transformer",
        "language_modeling_loss": 0.030759327244132186,
        "perplexity": 1.0312372832988292,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_final.pt"
      }
    ]
  },
  "finetuned": {
    "lstm": [
      {
        "model_name": "LSTM (Finetune Epoch 1)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.84656,
        "f1_score": 0.8491426773635362,
        "precision": 0.8350866336633663,
        "recall": 0.86368,
        "loss": 0.3492509490522125,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_finetuned_epoch_1.pt"
      },
      {
        "model_name": "LSTM (Finetune Epoch 2)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.86872,
        "f1_score": 0.8665311102074014,
        "precision": 0.8812241521918941,
        "recall": 0.85232,
        "loss": 0.3113165885410117,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_finetuned_epoch_2.pt"
      },
      {
        "model_name": "LSTM (Finetune Epoch 3)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.869,
        "f1_score": 0.869827894590405,
        "precision": 0.8643652737183032,
        "recall": 0.87536,
        "loss": 0.32969047499301335,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_finetuned_epoch_3.pt"
      },
      {
        "model_name": "LSTM (Best)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.869,
        "f1_score": 0.869827894590405,
        "precision": 0.8643652737183032,
        "recall": 0.87536,
        "loss": 0.32969047499301335,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_best.pt"
      },
      {
        "model_name": "LSTM (Finetune Best)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.869,
        "f1_score": 0.869827894590405,
        "precision": 0.8643652737183032,
        "recall": 0.87536,
        "loss": 0.32969047499301335,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_finetuned_best.pt"
      }
    ],
    "gpt": [
      {
        "model_name": "GPT (Finetune Epoch 1)",
        "display_name": "Transformer",
        "accuracy": 0.83928,
        "f1_score": 0.8528528528528528,
        "precision": 0.7864379305686884,
        "recall": 0.93152,
        "loss": 0.3641802322148057,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_finetuned_epoch_1.pt"
      },
      {
        "model_name": "GPT (Finetune Epoch 2)",
        "display_name": "Transformer",
        "accuracy": 0.8646,
        "f1_score": 0.8587994827514287,
        "precision": 0.8972369911967227,
        "recall": 0.82352,
        "loss": 0.3266899990622916,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_finetuned_epoch_2.pt"
      },
      {
        "model_name": "GPT (Finetune Epoch 3)",
        "display_name": "Transformer",
        "accuracy": 0.86508,
        "f1_score": 0.8596980158895221,
        "precision": 0.895416341738151,
        "recall": 0.82672,
        "loss": 0.3453250370676751,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_finetuned_epoch_3.pt"
      },
      {
        "model_name": "GPT (Best)",
        "display_name": "Transformer",
        "accuracy": 0.86508,
        "f1_score": 0.8596980158895221,
        "precision": 0.895416341738151,
        "recall": 0.82672,
        "loss": 0.3453250370676751,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_best.pt"
      },
      {
        "model_name": "GPT (Finetune Best)",
        "display_name": "Transformer",
        "accuracy": 0.86508,
        "f1_score": 0.8596980158895221,
        "precision": 0.895416341738151,
        "recall": 0.82672,
        "loss": 0.3453250370676751,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_finetuned_best.pt"
      }
    ]
  }
}