{
  "pretrained": {
    "lstm": [
      {
        "model_name": "LSTM (Pretrain Epoch 1)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 6.625988723366124,
        "perplexity": 754.4497860428868,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_1.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 2)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 5.906671827765787,
        "perplexity": 367.4810775861592,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_2.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 3)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 5.4583130976197065,
        "perplexity": 234.70117227374004,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_3.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 4)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 5.124970922044888,
        "perplexity": 168.1692515628007,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_4.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 5)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.968314636285138,
        "perplexity": 2.63350230785249,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_5.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 6)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.2684421620930836,
        "perplexity": 1.3079253271795552,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_6.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 7)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.10284810109882597,
        "perplexity": 1.1083230432366245,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_7.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 8)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.05574737816669379,
        "perplexity": 1.0573305452147777,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_8.pt"
      },
      {
        "model_name": "LSTM (Pretrain Final)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.05574737816669379,
        "perplexity": 1.0573305452147777,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstm_pretrained_final.pt"
      }
    ],
    "gpt": [
      {
        "model_name": "GPT (Pretrain Epoch 1)",
        "display_name": "Transformer",
        "language_modeling_loss": 6.54340405373057,
        "perplexity": 694.6471742638109,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_1.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 2)",
        "display_name": "Transformer",
        "language_modeling_loss": 5.9564787992246595,
        "perplexity": 386.2476713106769,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_2.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 3)",
        "display_name": "Transformer",
        "language_modeling_loss": 5.557154224177075,
        "perplexity": 259.08448985964407,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_3.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 4)",
        "display_name": "Transformer",
        "language_modeling_loss": 5.233661915845932,
        "perplexity": 187.47807698839907,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_4.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 5)",
        "display_name": "Transformer",
        "language_modeling_loss": 4.945555896516058,
        "perplexity": 140.5489598162815,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_5.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 6)",
        "display_name": "Transformer",
        "language_modeling_loss": 4.628916693341201,
        "perplexity": 102.40307007336654,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_6.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 7)",
        "display_name": "Transformer",
        "language_modeling_loss": 0.1801608850242226,
        "perplexity": 1.1974099929614885,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_7.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 8)",
        "display_name": "Transformer",
        "language_modeling_loss": 0.046398103272744046,
        "perplexity": 1.0474913376911879,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_8.pt"
      },
      {
        "model_name": "GPT (Pretrain Final)",
        "display_name": "Transformer",
        "language_modeling_loss": 0.046398103272744046,
        "perplexity": 1.0474913376911879,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_final.pt"
      }
    ]
  },
  "finetuned": {
    "lstm": [
      {
        "model_name": "LSTM (Finetune Epoch 1)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.82572,
        "f1_score": 0.8066391514667377,
        "precision": 0.9058108242798764,
        "recall": 0.72704,
        "loss": 0.39023241635573946,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_finetuned_epoch_1.pt"
      },
      {
        "model_name": "LSTM (Finetune Epoch 2)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.86292,
        "f1_score": 0.8552114580252651,
        "precision": 0.9061688602381592,
        "recall": 0.80968,
        "loss": 0.33207811618133276,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_finetuned_epoch_2.pt"
      },
      {
        "model_name": "LSTM (Finetune Epoch 3)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.87028,
        "f1_score": 0.867789147539647,
        "precision": 0.8847784520741542,
        "recall": 0.85144,
        "loss": 0.32886217888015923,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_finetuned_epoch_3.pt"
      },
      {
        "model_name": "LSTM (Best)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.87028,
        "f1_score": 0.867789147539647,
        "precision": 0.8847784520741542,
        "recall": 0.85144,
        "loss": 0.32886217888015923,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_best.pt"
      },
      {
        "model_name": "LSTM (Finetune Best)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.87028,
        "f1_score": 0.867789147539647,
        "precision": 0.8847784520741542,
        "recall": 0.85144,
        "loss": 0.32886217888015923,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_finetuned_best.pt"
      }
    ],
    "gpt": [
      {
        "model_name": "GPT (Finetune Epoch 1)",
        "display_name": "Transformer",
        "accuracy": 0.83576,
        "f1_score": 0.8192145121521662,
        "precision": 0.9109870740305523,
        "recall": 0.74424,
        "loss": 0.3786050601840934,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_finetuned_epoch_1.pt"
      },
      {
        "model_name": "GPT (Finetune Epoch 2)",
        "display_name": "Transformer",
        "accuracy": 0.85892,
        "f1_score": 0.8496141218607428,
        "precision": 0.9096138044371405,
        "recall": 0.79704,
        "loss": 0.34523008153071183,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_finetuned_epoch_2.pt"
      },
      {
        "model_name": "GPT (Finetune Epoch 3)",
        "display_name": "Transformer",
        "accuracy": 0.86872,
        "f1_score": 0.8660736146249898,
        "precision": 0.8838913876395136,
        "recall": 0.84896,
        "loss": 0.3445595022733978,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_finetuned_epoch_3.pt"
      },
      {
        "model_name": "GPT (Best)",
        "display_name": "Transformer",
        "accuracy": 0.86872,
        "f1_score": 0.8660736146249898,
        "precision": 0.8838913876395136,
        "recall": 0.84896,
        "loss": 0.3445595022733978,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_best.pt"
      },
      {
        "model_name": "GPT (Finetune Best)",
        "display_name": "Transformer",
        "accuracy": 0.86872,
        "f1_score": 0.8660736146249898,
        "precision": 0.8838913876395136,
        "recall": 0.84896,
        "loss": 0.3445595022733978,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_finetuned_best.pt"
      }
    ]
  }
}