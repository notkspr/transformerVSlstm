{
  "pretrained": {
    "lstm": [
      {
        "model_name": "LSTM (Pretrain Epoch 1)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 6.6154298721605045,
        "perplexity": 746.5255719307933,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_1.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 2)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 5.896332989832398,
        "perplexity": 363.7013230846164,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_2.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 3)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 5.4358639899332815,
        "perplexity": 229.49104059418724,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_3.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 4)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 1.1720434761351082,
        "perplexity": 3.2285834353673684,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_4.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 5)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.22100708866195315,
        "perplexity": 1.247332272449549,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_5.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 6)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.07469915415925585,
        "perplexity": 1.0775599226948305,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_6.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 7)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.03888855627767599,
        "perplexity": 1.0396546142136778,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_7.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 8)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.02668477089446821,
        "perplexity": 1.0270439975690644,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_8.pt"
      },
      {
        "model_name": "LSTM (Pretrain Final)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.02668477089446821,
        "perplexity": 1.0270439975690644,
        "total_tokens": 2554080,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstm_pretrained_final.pt"
      }
    ],
    "gpt": [
      {
        "model_name": "GPT (Pretrain Epoch 1)",
        "display_name": "Transformer",
        "language_modeling_loss": 6.50196539824176,
        "perplexity": 666.4501867338064,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_1.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 2)",
        "display_name": "Transformer",
        "language_modeling_loss": 5.928355678631242,
        "perplexity": 375.53650316301866,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_2.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 3)",
        "display_name": "Transformer",
        "language_modeling_loss": 5.508115370562122,
        "perplexity": 246.6857774215053,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_3.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 4)",
        "display_name": "Transformer",
        "language_modeling_loss": 5.15178749971329,
        "perplexity": 172.73998719325562,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_4.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 5)",
        "display_name": "Transformer",
        "language_modeling_loss": 4.636317799805076,
        "perplexity": 103.16377766374207,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_5.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 6)",
        "display_name": "Transformer",
        "language_modeling_loss": 0.19303526876458696,
        "perplexity": 1.2129255711511884,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_6.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 7)",
        "display_name": "Transformer",
        "language_modeling_loss": 0.05351157557622642,
        "perplexity": 1.0549692035733442,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_7.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 8)",
        "display_name": "Transformer",
        "language_modeling_loss": 0.025850466482198922,
        "perplexity": 1.0261874875750134,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_8.pt"
      },
      {
        "model_name": "GPT (Pretrain Final)",
        "display_name": "Transformer",
        "language_modeling_loss": 0.025850466482198922,
        "perplexity": 1.0261874875750134,
        "total_tokens": 2554080,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_pretrained_final.pt"
      }
    ]
  },
  "finetuned": {
    "lstm": [
      {
        "model_name": "LSTM (Finetune Epoch 1)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.84372,
        "f1_score": 0.8400278426073783,
        "precision": 0.8603539377673405,
        "recall": 0.82064,
        "loss": 0.35548241548907117,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_finetuned_epoch_1.pt"
      },
      {
        "model_name": "LSTM (Finetune Epoch 2)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.8674,
        "f1_score": 0.866722952599204,
        "precision": 0.8711710983593308,
        "recall": 0.86232,
        "loss": 0.3134797696248078,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_finetuned_epoch_2.pt"
      },
      {
        "model_name": "LSTM (Finetune Epoch 3)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.86872,
        "f1_score": 0.8705631803123521,
        "precision": 0.8585096453018046,
        "recall": 0.88296,
        "loss": 0.3321578414238932,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_finetuned_epoch_3.pt"
      },
      {
        "model_name": "LSTM (Best)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.86872,
        "f1_score": 0.8705631803123521,
        "precision": 0.8585096453018046,
        "recall": 0.88296,
        "loss": 0.3321578414238932,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_best.pt"
      },
      {
        "model_name": "LSTM (Finetune Best)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.86872,
        "f1_score": 0.8705631803123521,
        "precision": 0.8585096453018046,
        "recall": 0.88296,
        "loss": 0.3321578414238932,
        "total_parameters": 6830978,
        "checkpoint_path": "checkpoints/lstmclassifier_finetuned_best.pt"
      }
    ],
    "gpt": [
      {
        "model_name": "GPT (Finetune Epoch 1)",
        "display_name": "Transformer",
        "accuracy": 0.84936,
        "f1_score": 0.8566534713763703,
        "precision": 0.8170926517571885,
        "recall": 0.90024,
        "loss": 0.344040522799658,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_finetuned_epoch_1.pt"
      },
      {
        "model_name": "GPT (Finetune Epoch 2)",
        "display_name": "Transformer",
        "accuracy": 0.86304,
        "f1_score": 0.8575944102478789,
        "precision": 0.8931046431046431,
        "recall": 0.8248,
        "loss": 0.34045535343630084,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_finetuned_epoch_2.pt"
      },
      {
        "model_name": "GPT (Finetune Epoch 3)",
        "display_name": "Transformer",
        "accuracy": 0.8652,
        "f1_score": 0.8657156518967166,
        "precision": 0.8624166402032392,
        "recall": 0.86904,
        "loss": 0.34243864613725705,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_finetuned_epoch_3.pt"
      },
      {
        "model_name": "GPT (Best)",
        "display_name": "Transformer",
        "accuracy": 0.8652,
        "f1_score": 0.8657156518967166,
        "precision": 0.8624166402032392,
        "recall": 0.86904,
        "loss": 0.34243864613725705,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_best.pt"
      },
      {
        "model_name": "GPT (Finetune Best)",
        "display_name": "Transformer",
        "accuracy": 0.8652,
        "f1_score": 0.8657156518967166,
        "precision": 0.8624166402032392,
        "recall": 0.86904,
        "loss": 0.34243864613725705,
        "total_parameters": 6895746,
        "checkpoint_path": "checkpoints/gpt_finetuned_best.pt"
      }
    ]
  }
}