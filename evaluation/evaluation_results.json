{
  "pretrained": {
    "lstm": [
      {
        "model_name": "LSTM (Pretrain Epoch 1)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 6.6609008509642,
        "perplexity": 781.2544140074608,
        "total_tokens": 2554080,
        "total_parameters": 6632322,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_1.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 2)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 5.9668224844962925,
        "perplexity": 390.26362975857705,
        "total_tokens": 2554080,
        "total_parameters": 6632322,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_2.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 3)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 5.499294821623784,
        "perplexity": 244.5194416302337,
        "total_tokens": 2554080,
        "total_parameters": 6632322,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_3.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 4)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 1.102628673337827,
        "perplexity": 3.0120733834552733,
        "total_tokens": 2554080,
        "total_parameters": 6632322,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_4.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 5)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.2958041959127803,
        "perplexity": 1.3442069298515005,
        "total_tokens": 2554080,
        "total_parameters": 6632322,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_5.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 6)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.11529113423482627,
        "perplexity": 1.1222001008858875,
        "total_tokens": 2554080,
        "total_parameters": 6632322,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_6.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 7)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.061167130899277465,
        "perplexity": 1.0630765722842297,
        "total_tokens": 2554080,
        "total_parameters": 6632322,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_7.pt"
      },
      {
        "model_name": "LSTM (Pretrain Epoch 8)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.04055177215130845,
        "perplexity": 1.0413852230602387,
        "total_tokens": 2554080,
        "total_parameters": 6632322,
        "checkpoint_path": "checkpoints/lstmclassifier_pretrained_epoch_8.pt"
      },
      {
        "model_name": "LSTM (Pretrain Final)",
        "display_name": "LSTM with Attention",
        "language_modeling_loss": 0.04055177215130845,
        "perplexity": 1.0413852230602387,
        "total_tokens": 2554080,
        "total_parameters": 6632322,
        "checkpoint_path": "checkpoints/lstm_pretrained_final.pt"
      }
    ],
    "gpt": [
      {
        "model_name": "GPT (Pretrain Epoch 1)",
        "display_name": "Transformer",
        "language_modeling_loss": 6.644755937491253,
        "perplexity": 768.7424035348739,
        "total_tokens": 2554080,
        "total_parameters": 6697474,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_1.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 2)",
        "display_name": "Transformer",
        "language_modeling_loss": 6.040303178653596,
        "perplexity": 420.02035679131245,
        "total_tokens": 2554080,
        "total_parameters": 6697474,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_2.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 3)",
        "display_name": "Transformer",
        "language_modeling_loss": 5.583106548163541,
        "perplexity": 265.89634387741944,
        "total_tokens": 2554080,
        "total_parameters": 6697474,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_3.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 4)",
        "display_name": "Transformer",
        "language_modeling_loss": 5.230601486886383,
        "perplexity": 186.90519073828676,
        "total_tokens": 2554080,
        "total_parameters": 6697474,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_4.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 5)",
        "display_name": "Transformer",
        "language_modeling_loss": 4.865514065809311,
        "perplexity": 129.7376151444051,
        "total_tokens": 2554080,
        "total_parameters": 6697474,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_5.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 6)",
        "display_name": "Transformer",
        "language_modeling_loss": 0.3075695109025688,
        "perplexity": 1.360115348061599,
        "total_tokens": 2554080,
        "total_parameters": 6697474,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_6.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 7)",
        "display_name": "Transformer",
        "language_modeling_loss": 0.058243751407239086,
        "perplexity": 1.0599733342156723,
        "total_tokens": 2554080,
        "total_parameters": 6697474,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_7.pt"
      },
      {
        "model_name": "GPT (Pretrain Epoch 8)",
        "display_name": "Transformer",
        "language_modeling_loss": 0.024914441950571766,
        "perplexity": 1.025227400315306,
        "total_tokens": 2554080,
        "total_parameters": 6697474,
        "checkpoint_path": "checkpoints/gpt_pretrained_epoch_8.pt"
      },
      {
        "model_name": "GPT (Pretrain Final)",
        "display_name": "Transformer",
        "language_modeling_loss": 0.024914441950571766,
        "perplexity": 1.025227400315306,
        "total_tokens": 2554080,
        "total_parameters": 6697474,
        "checkpoint_path": "checkpoints/gpt_pretrained_final.pt"
      }
    ]
  },
  "finetuned": {
    "lstm": [
      {
        "model_name": "LSTM (Finetune Epoch 1)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.83732,
        "f1_score": 0.838155119582952,
        "precision": 0.8338744160266054,
        "recall": 0.84248,
        "loss": 0.36947282776236534,
        "total_parameters": 6632322,
        "checkpoint_path": "checkpoints/lstmclassifier_finetuned_epoch_1.pt"
      },
      {
        "model_name": "LSTM (Finetune Epoch 2)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.86664,
        "f1_score": 0.864921805364233,
        "precision": 0.8762108028238385,
        "recall": 0.85392,
        "loss": 0.3177475904226494,
        "total_parameters": 6632322,
        "checkpoint_path": "checkpoints/lstmclassifier_finetuned_epoch_2.pt"
      },
      {
        "model_name": "LSTM (Finetune Epoch 3)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.86484,
        "f1_score": 0.8718376635691257,
        "precision": 0.8289217454020916,
        "recall": 0.91944,
        "loss": 0.34100375571847913,
        "total_parameters": 6632322,
        "checkpoint_path": "checkpoints/lstmclassifier_finetuned_epoch_3.pt"
      },
      {
        "model_name": "LSTM (Best)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.86664,
        "f1_score": 0.864921805364233,
        "precision": 0.8762108028238385,
        "recall": 0.85392,
        "loss": 0.3177475904226494,
        "total_parameters": 6632322,
        "checkpoint_path": "checkpoints/lstmclassifier_best.pt"
      },
      {
        "model_name": "LSTM (Finetune Best)",
        "display_name": "LSTM with Attention",
        "accuracy": 0.86664,
        "f1_score": 0.864921805364233,
        "precision": 0.8762108028238385,
        "recall": 0.85392,
        "loss": 0.3177475904226494,
        "total_parameters": 6632322,
        "checkpoint_path": "checkpoints/lstmclassifier_finetuned_best.pt"
      }
    ],
    "gpt": [
      {
        "model_name": "GPT (Finetune Epoch 1)",
        "display_name": "Transformer",
        "accuracy": 0.8322,
        "f1_score": 0.8406457739791073,
        "precision": 0.8003616636528029,
        "recall": 0.8852,
        "loss": 0.38079355651384117,
        "total_parameters": 6697474,
        "checkpoint_path": "checkpoints/gpt_finetuned_epoch_1.pt"
      },
      {
        "model_name": "GPT (Finetune Epoch 2)",
        "display_name": "Transformer",
        "accuracy": 0.84444,
        "f1_score": 0.8346443301160764,
        "precision": 0.8907341864052999,
        "recall": 0.7852,
        "loss": 0.36758629034947404,
        "total_parameters": 6697474,
        "checkpoint_path": "checkpoints/gpt_finetuned_epoch_2.pt"
      },
      {
        "model_name": "GPT (Finetune Epoch 3)",
        "display_name": "Transformer",
        "accuracy": 0.8568,
        "f1_score": 0.8539252488983189,
        "precision": 0.871419053964024,
        "recall": 0.83712,
        "loss": 0.35517906073642813,
        "total_parameters": 6697474,
        "checkpoint_path": "checkpoints/gpt_finetuned_epoch_3.pt"
      },
      {
        "model_name": "GPT (Best)",
        "display_name": "Transformer",
        "accuracy": 0.8568,
        "f1_score": 0.8539252488983189,
        "precision": 0.871419053964024,
        "recall": 0.83712,
        "loss": 0.35517906073642813,
        "total_parameters": 6697474,
        "checkpoint_path": "checkpoints/gpt_best.pt"
      },
      {
        "model_name": "GPT (Finetune Best)",
        "display_name": "Transformer",
        "accuracy": 0.8568,
        "f1_score": 0.8539252488983189,
        "precision": 0.871419053964024,
        "recall": 0.83712,
        "loss": 0.35517906073642813,
        "total_parameters": 6697474,
        "checkpoint_path": "checkpoints/gpt_finetuned_best.pt"
      }
    ]
  }
}